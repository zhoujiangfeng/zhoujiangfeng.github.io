<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>标签: DA - 都灵的夏天</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="都灵的夏天"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="都灵的夏天"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="日拱一卒，功不唐捐"><meta property="og:type" content="blog"><meta property="og:title" content="都灵的夏天"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="都灵的夏天"><meta property="og:description" content="日拱一卒，功不唐捐"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="周江峰"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"都灵的夏天","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"周江峰"},"publisher":{"@type":"Organization","name":"都灵的夏天","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"日拱一卒，功不唐捐"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"><link rel="alternate" href="/atom.xml" title="都灵的夏天" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="都灵的夏天" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">所有文章</a><a class="navbar-item" href="/categories">目录</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">DA</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-07-02T16:00:00.000Z" title="7/3/2022, 12:00:00 AM">2022-07-03</time>发表</span><span class="level-item"><time dateTime="2022-07-02T17:00:02.592Z" title="7/3/2022, 1:00:02 AM">2022-07-03</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E5%AD%A6%E6%9C%AF%E5%9E%83%E5%9C%BE%E5%88%B6%E9%80%A0/">学术垃圾制造</a></span><span class="level-item">3 分钟读完 (大约382个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/07/03/%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AE%BA%E6%96%87%E6%8A%95%E9%80%92%E5%A4%B1%E8%B4%A5%E7%BB%8F%E5%8E%86/">第一次论文失败经历</a></h1><div class="content"><p>去年九月份，采购问答机器人项目由于缺乏数据，原始文件就几百条，导致模型准确率较低，老板催促解决这个问题，在组会上提出了数据扩充技术，下来实验，采用回译尝试了一下，遂进入数据增强方面工作，由于国庆结束，去兵科院实习了三个月，在实习之余完成了 基本实验，开年2-4月继续实验，改论文，4月初在老板的要求下投了一个CCF C类期刊，计算机应用，感觉这个名字还挺好听，当时幻想着一投就中，所以改了又改，图画了又画（全文唯一满意的就是模型图了）。然后7月第一天，下午去实验室，收到邮件，让修改后录增刊，给老板发消息，老板说不投了，再想办法。</p>
<hr>
<p>全过程</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220703005118.png" alt="投递全过程"></p>
<p>耗费了3个月，6-7月其实光在等结果了，无心第二篇的写作。ε=(´ο｀*)))唉</p>
<p>本来6月10号三审就结束了，中间直接停滞了半个月。</p>
<p>希望下次运气好一点。</p>
<p>近期再写一篇，继续投，缓解一下焦虑。没论文在手里可太难了。都不能全身心投入工作准备中…</p>
<p>祝好运！加油</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-06-13T16:00:00.000Z" title="6/14/2022, 12:00:00 AM">2022-06-14</time>发表</span><span class="level-item"><time dateTime="2022-06-22T05:11:00.007Z" title="6/22/2022, 1:11:00 PM">2022-06-22</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/DA/">DA</a></span><span class="level-item">15 分钟读完 (大约2258个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/06/14/%E3%80%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%8D2022NAAC%EF%BC%9ATreeMix/">TreeMix：基于组合的数据增强方法</a></h1><div class="content"><h2 id="Publish"><a href="#Publish" class="headerlink" title="Publish"></a>Publish</h2><p>NAACL2022</p>
<h2 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h2><p>TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>数据增强是解决过度拟合问题的一种有效方法。前人针对自然语言处理提出了不同的数据扩充策略，如噪声注入、单词替换、回译等。虽然有效，但它们<strong>忽略了语言的一个重要特征-组合性</strong>，<strong>复杂表达的意义是从其子部分建立起来的</strong>。受此启发，我们提出了一种用于自然语言理解的成分数据扩充方法TreeMix。具体地说，<strong>TreeMix利用选区分析树将句子分解成构成子结构，并利用Mixup数据增强技术对它们进行重组以生成新的句子</strong>。与以前的方法相比，TreeMix在生成的样本中引入了更大的<strong>多样性</strong>，并鼓励模型学习NLP数据的<strong>组合性</strong>。在文本分类和SCAN的大量实验表明，TreeMix的性能优于目前最先进的数据增强方法。</p>
<h2 id="Solution-problem"><a href="#Solution-problem" class="headerlink" title="Solution problem"></a>Solution problem</h2><p>合成性是语言的一个关键方面，因为复句的意义是从它的子部分建立起来的。先前的工作还表明，语法树(例如，基于树的LSTM)有助于对句子结构进行建模，以便更好地进行文本分类。然而，在语言技术社区中，除了在语义分析方面的一些例外情况外，利用组合结构进行数据扩充并没有受到太多关注</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220613135323.png" alt="image-20220613135315056"></p>
<p>我们提出了一种用于自然语言理解的成分数据增强方法，即TreeMix(图1)。TreeMix是一种输入级混合方法，它利用成分分析信息，将来自不同句子的不同片段(子树的短语)进行重组，以创建训练集中从未见过的新示例；同时还将基于这些片段策略性地创建新的软标签。这样，TreeMix不仅利用了构成语言的特征来增加扩充的多样性，而且为这些混合的例子提供了合理的软标签。</p>
<p>mixup定义为</p>
<script type="math/tex; mode=display">
\tilde{x}=\lambda x_{i}+(1-\lambda) x_{j}</script><script type="math/tex; mode=display">
\tilde{y}=\lambda y_{i}+(1-\lambda) y_{j}</script><p>其中$(x_i,x_j),(y_i,y_j)$为从训练数据中随机抽出两个目标特征向量,$\lambda\in[0,1]$</p>
<p>我们通过融入语言的组合性来改进Mixup，这是泛化所必需的一个关键特征，但神经模型往往无法捕捉到这一点。我们新提出的方法TreeMix不是用整个样本进行内插，而是<strong>通过删除句子的短语并重新插入其他句子的子部分来创建新句子</strong>。TreeMix利用选民树将句子分解成有意义的组成部分，然后将这些组成部分移除并重新组合，以生成新的扩充样本。我们的目标是通过对TreeMix生成的大量样本进行训练来提高模型的组合性泛化能力。一个使用TreeMix进行单句分类的例子如上图所示。</p>
<h3 id="TreeMix-详细过程"><a href="#TreeMix-详细过程" class="headerlink" title="TreeMix 详细过程"></a>TreeMix 详细过程</h3><p>${x}<em>{i}=\left{x</em>{i}^{1}, x<em>{i}^{2}, \ldots, x</em>{i}^{l}\right}$表示长度为$l$的序列，其对应的one-hot编码label为$y<em>i$,我们在$x_i$上运行一个解析器得到它的解析树$T(x_i)$,为了获取序列中有意义的子部分，采用递归遍历解析树，获得所有具有一个以上child的子树。表示子树的集合为$S(x_i)= {t_i^k}$.其中$t_i^k$表示样本$x_i$的第k个子树，对于子树$t_i^k$连续覆盖了$x_i$的$t</em>{i}^{k} \triangleq\left[x<em>{i}^{r</em>{k} }, \ldots, x<em>{i}^{s</em>{k} }\right]$,索引$r_k$为开始，$s_k$为结束。例如图一左侧所示，例句子树可以cover span 的有1.<em>this poor film</em>,2. <em>in this poor film</em>, 3.<em>no interest …etc</em></p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614152117.png" style="zoom:50%;" /></p>
<p>对于给定的样本$(x_i,y_i)$，我们从训练集中随机抽取另一个数据点$(x_j, y_j)$。我们对这两个句子运行选区解析器，得到它们的子树集$S(x_i)$和$S(x_j)$，我们可以对要交换的子树进行采样。我们引入两个额外的超参数$λ_L$和$λ_U$来约束待采样子树的长度。$λ_L$和$λ_U$，用子树与原始句子的长度之比来衡量要采样子树的上下限。直观地说，$λ$控制着我们想要交换的短语的粒度。我们希望交换的长度是合理的。如果它太短，那么交换不能给增强样本引入足够的多样性;否则，如果太长，这个过程可能会给原句注入太多噪音。我们设置λ为比率，以便与原句子的长度不变。表2显示了一些具有不同长度约束的子树示例。我们将长度受限子树集合定义为:</p>
<script type="math/tex; mode=display">
S_{\lambda}(\mathbf{x}) \triangleq\left\{t \mid t \in S(\mathbf{x})\right., s.t. \left.\frac{|t|}{|\mathbf{x}|} \in\left[\lambda_{L}, \lambda_{U}\right]\right\}</script><p>其中$|·|$表示序列或子树的长度，对于两个句子$x<em>i$和$x_j$,我们随机采样两个子树$t</em>{i}^{k} \in S<em>{\lambda}\left(\mathbf{x}</em>{i}\right)$和$t<em>{j}^{l} \in S</em>{\lambda}\left(\mathbf{x}_{j}\right)$并且通过$t_j^l$替换$t_i^k$构建新的样本。例如</p>
<script type="math/tex; mode=display">
\overline{\mathbf{x}} \triangleq[x_{i}^{1}, \ldots, x_{i}^{r_{k}-1}, \underbrace{x_{j}^{r_{l}}, \ldots, x_{j}^{s_{l}}}_{t_{j}^{l}}, x_{i}^{s_{k}+1}, \ldots x_{i}^{l}]</script><p>其中$t<em>{j}^{l}=\left[x</em>{j}^{r<em>{l} }, \ldots, x</em>{j}^{s<em>{l} }\right]$替换$t</em>{i}^{k}=$ $\left[x<em>{i}^{r</em>{k}}, \ldots, x<em>{i}^{s</em>{k} }\right]$如上图1所示<em>a touching transcend love story</em> 替换<em>this poor film.</em></p>
<h4 id="TreeMix制作标签"><a href="#TreeMix制作标签" class="headerlink" title="TreeMix制作标签"></a>TreeMix制作标签</h4><p>为扩充的样本$\overline{x}$创建有效标签是一个具有挑战性的问题。类似于Mixup，我们使用原始的凸组合两个句子的标签作为扩充样本的标签。</p>
<script type="math/tex; mode=display">
\overline{\mathbf{y}}=\frac{l_{i}-\left|t_{i}^{k}\right|}{l_{i}-\left|t_{i}^{k}\right|+\left|t_{j}^{l}\right|} \mathbf{y}_{i}+\frac{\left|t_{j}^{l}\right|}{l_{i}-\left|t_{i}^{k}\right|+\left|t_{j}^{l}\right|} \mathbf{y}_{j}</script><p>其中$l_i$为$x_i$的长度，$|t_i^k|$为子树的长度，在新的句子中,从$x_i$中保留$l_i-|t_i^k|$个words，从句子$x_j$插入$|t_j^l|$个words。</p>
<p>$\frac{l<em>{i}-\left|t</em>{i}^{k}\right|}{l<em>{i}-\left|t</em>{i}^{k}\right|+\left|t_{j}^{l}\right|}$是来自$x_i$的words的分数，其可以决定$y_i$的权重，然后，基于标签的变化与原始句子中的长度变化成比例的猜想来创建标签。附录提供样本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614162151.png" alt="image-20220614162150953"></p>
<h4 id="组合算法"><a href="#组合算法" class="headerlink" title="组合算法"></a>组合算法</h4><p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614163620.png" style="zoom:50%;" /></p>
<p>我们的主要算法如算法1所示。虽然TreeMix创建的句子<strong>并不都是流畅的甚至有效的新句子</strong>，但它们<strong>包含具有不同含义的子部分</strong>，这<strong>鼓励模型以组合的方式构建丰富的句子表示</strong>。需要注意的是，扩展后的标签是<strong>原始标签的凸组合</strong>，只有当模型学习到<strong>两个部分的表示在一起</strong>时，它们才能<strong>预测具有不同权重的两个标签</strong>。</p>
<h4 id="Training-Objective"><a href="#Training-Objective" class="headerlink" title="Training Objective"></a>Training Objective</h4><p>我们的模型是在原始样本和增强样本的组合上训练，以获得正则化和噪声注入之间的权衡。最终的培训目标是:</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal{L}=& \underset{(\mathbf{x}, \mathbf{y}) \sim D}{\mathbb{E}}\left[-\mathbf{y}^{\top} \log P_{\theta}(\mathbf{y} \mid \mathbf{x})\right]
+\gamma \underset{(\overline{\mathbf{x} }, \overline{\mathbf{y} }) \sim D^{\prime} }{\mathbb{E}}\left[-\overline{\mathbf{y} }^{\top} \log P_{\theta}(\overline{\mathbf{y} } \mid \overline{\mathbf{x} })\right]
\end{aligned}</script><p>$\gamma$i是增强样本的权重</p>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul>
<li><p>数据集</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614164635.png" alt="image-20220614164635190" style="zoom:50%;" /></p>
</li>
</ul>
<ul>
<li><p><strong>Baseline</strong></p>
<p>| approaches       | 简介                                                         |<br>| ———————— | —————————————————————————————— |<br>| BERT             |                                                              |<br>| EDA              | 由四个简单操作组成：同义词替换、随机插入、随机交换和随机删除。 |<br>| AEDA             | 在文本中随机插入标点符号的AEDA                               |<br>| Back Translation | 将句子翻译成临时语言(EN-DE)，然后将先前翻译的文本翻译回源语言(DE-EN) |<br>| GPT3Mix          | 设计提示并利用GPT3生成新的示例来训练模型。                   |<br>| SSMix            | 通过在给定类的所有示例前添加类标签来为条件BART。BARTword屏蔽了单个单词，而BARTspan屏蔽了连续的区块。 |<br>| EmbedMix         |                                                              |<br>| Tmix             | 首先对两个输入分别编码，然后在某一编码器层a处对两个嵌入进行线性插值，最终向前传递组合嵌入到其余层中。 |</p>
</li>
<li><p><strong>结果</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614170349.png" alt="image-20220614170349622" style="zoom:50%;" /></p>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614170416.png" alt="image-20220614170416075"></p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220614170443.png" alt="image-20220614170443863"></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>没找到代码，自己摸索了。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2022-05-25T16:00:00.000Z" title="5/26/2022, 12:00:00 AM">2022-05-26</time>发表</span><span class="level-item"><time dateTime="2022-06-22T03:44:58.695Z" title="6/22/2022, 11:44:58 AM">2022-06-22</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/DA/">DA</a></span><span class="level-item">6 分钟读完 (大约942个字)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2022/05/26/%E3%80%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%8D2022NAACL%EF%BC%9ATextSmoth/">Text Smoothing：一种数据结合mix-up的数据增强方法</a></h1><div class="content"><h2 id="Publish"><a href="#Publish" class="headerlink" title="Publish"></a>Publish</h2><p>2022ACL</p>
<h2 id="title"><a href="#title" class="headerlink" title="title"></a>title</h2><p>Text Smoothing: Enhance Various Data Augmentation Methods on Text Classification Tasks</p>
<h2 id="solution-problem"><a href="#solution-problem" class="headerlink" title="solution problem"></a>solution problem</h2><p>进入神经网络之前，标记通常被转换为对应的One-hot表示，这是词汇表的离散分布。平滑表示是从预先训练的MLM中获得候选token的概率，它可以被视为对onr-hot表示的更多信息的替代。我们提出了一种有效的数据增强方法，称为文本平滑，通过将句子从其one-hot表示转换为可控的平滑表示。我们在低资源条件下对不同基准的文本平滑进行了评估。实验结果表明，文本平滑方法的性能明显优于各种主流数据增强方法。此外，文本平滑可以与这些数据增强方法相结合，以获得更好的性能。</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220526171229.png" alt="image-20220526171221247" style="zoom:50%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220526175945.png" alt="image-20220526175945737" style="zoom:50%;" /></p>
<p>文本平滑代码：Pytorch</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sentence = <span class="string">&quot;My favorite fruit is pear .&quot;</span></span><br><span class="line">lambd = <span class="number">0.1</span> <span class="comment"># interpolation hyperparameter</span></span><br><span class="line">mlm.train() <span class="comment"># enable dropout, dynamically mask</span></span><br><span class="line">tensor_input = tokenizer(sentence, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line">onehot_repr = convert_to_onehot(**tensor_input)</span><br><span class="line">smoothed_repr = softmax(mlm(**tensor_input).logits[<span class="number">0</span>])</span><br><span class="line">interpolated_repr = lambd * onehot_repr + (<span class="number">1</span> - lambd) * smoothed_repr</span><br></pre></td></tr></table></figure>
<ol>
<li><p>使用BERT作为MLM，给定下游数据集命名为：$D={t<em>i,p_i,s_i,l_i}</em>{i=1}^{N}$ ,N表示样本数量，$t_i$表示文本one-hot 编码，$p_i$表示$t_i$位置编码，$s_i$表示$t_i$的段编码，$l_i$表示实例标签。</p>
</li>
<li><p>将$t_i,p_i,s_i$送入BERT</p>
</li>
<li><p>取回BERT中Transformer-encoder最后一层的输出表示为</p>
<script type="math/tex; mode=display">
\overrightarrow{t_i}=BERT(t_i)</script><p>其中$\overrightarrow{t_i}$形状为[seq_len,emb_size]</p>
</li>
<li><p>然后乘以$\overrightarrow{t_i}$乘以BERT中词嵌入矩阵$W$,其形状为[vocab_size,embed_size]</p>
<script type="math/tex; mode=display">
MLM(t_i)=softmax(\overrightarrow(t_i)W^T)</script><p>其中$MLM(t_i)$中每一行是token词汇表中的概率分布，表示了预训练BERT学习到输入文本所在位置的包含上下文 的标记选项（信息）。</p>
</li>
<li></li>
</ol>
<ol>
<li><p>mixup定义为</p>
<script type="math/tex; mode=display">
\tilde{x}=\lambda x_{i}+(1-\lambda) x_{j}</script><script type="math/tex; mode=display">
\tilde{y}=\lambda y_{i}+(1-\lambda) y_{j}</script><p>其中$(x_i,x_j),(y_i,y_j)$为从训练数据中随机抽出两个目标特征向量,$\lambda\in[0,1]$在文本平滑中，One-hot表示和平滑表示来自相同的原始输入，标签相同，其内部插入操作不会改变标签，因此mixup操作可以简化为</p>
<script type="math/tex; mode=display">
\widetilde{t_{i}}=\lambda \cdot t_{i}+(1-\lambda) \cdot \operatorname{MLM}\left(t_{i}\right)</script><p>其中$t_i$为one-hot表示，$MLM(t_i)$为平滑表示，$\widetilde{t_i}$为联合插入表示，$\lambda$为用于控制插入的超参数。下游任务中我们使用联合表示代替one-hot变化表示作为输入。</p>
</li>
</ol>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><ul>
<li><p>数据集</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220526201719.png" alt="image-20220526201719743" style="zoom:50%;" /></p>
</li>
</ul>
<ul>
<li><p>Baseline</p>
<p>| approaches              | 简介                                                         |<br>| ———————————- | —————————————————————————————— |<br>| EDA                     | 由四个简单操作组成：同义词替换、随机插入、随机交换和随机删除。 |<br>| Back Translation        | 将句子翻译成临时语言(EN-DE)，然后将先前翻译的文本翻译回源语言(DE-EN) |<br>| CBERT                   | 用预先训练的BERT mask一些标记并预测它们的上下文替换。        |<br>| BERTexpand, BERTprepend | 通过在给定类的所有示例中添加类标签来满足BERT条件。“expand”标签以 模拟 词汇表，而“prepend”则没有 |<br>| GPT2context             | 为预先训练的GPT模型提供提示，并持续生成，直到[EOS]token      |<br>| BARTword, BARTspan      | 通过在给定类的所有示例前添加类标签来为条件BART。BARTword屏蔽了单个单词，而BARTspan屏蔽了连续的区块。 |</p>
</li>
<li><p>结果</p>
<p><img src="https://cdn.jsdelivr.net/gh/zhoujiangfeng/images@main/20220526202740.png" alt="image-20220526202740487"></p>
</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>小数据，可控，目前优于其他，未来，结合其他DA=顶会。我也想发顶会啊。</p>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="都灵的夏天"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">都灵的夏天</p><p class="is-size-6 is-block">天道酬勤</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>ChongQing</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">11</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">13</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/BERT/"><span class="level-start"><span class="level-item">BERT</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DA/"><span class="level-start"><span class="level-item">DA</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/GAN/"><span class="level-start"><span class="level-item">GAN</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/code/"><span class="level-start"><span class="level-item">code</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%AD%A6%E6%9C%AF%E5%9E%83%E5%9C%BE%E5%88%B6%E9%80%A0/"><span class="level-start"><span class="level-item">学术垃圾制造</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><span class="level-start"><span class="level-item">数据增强</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%9C%AD%E8%AE%B0/"><span class="level-start"><span class="level-item">札记</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%A0%94%E7%A9%B6%E7%82%B9/"><span class="level-start"><span class="level-item">研究点</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-07-02T16:00:00.000Z">2022-07-03</time></p><p class="title"><a href="/2022/07/03/%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%AE%BA%E6%96%87%E6%8A%95%E9%80%92%E5%A4%B1%E8%B4%A5%E7%BB%8F%E5%8E%86/">第一次论文失败经历</a></p><p class="categories"><a href="/categories/%E5%AD%A6%E6%9C%AF%E5%9E%83%E5%9C%BE%E5%88%B6%E9%80%A0/">学术垃圾制造</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-21T16:00:00.000Z">2022-06-22</time></p><p class="title"><a href="/2022/06/22/%E6%8D%A2%E4%B8%BB%E9%A2%98%E5%90%8E%E7%AC%AC%E4%B8%80%E7%AF%87/">换了新主题，显示不了LaTeX公式</a></p><p class="categories"><a href="/categories/%E6%9C%AD%E8%AE%B0/">札记</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-15T16:00:00.000Z">2022-06-16</time></p><p class="title"><a href="/2022/06/16/%E3%80%8Cpytorch%E3%80%8D%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/">样例-快速入门Pytorch</a></p><p class="categories"><a href="/categories/code/">code</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-06-13T16:00:00.000Z">2022-06-14</time></p><p class="title"><a href="/2022/06/14/%E3%80%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E3%80%8D2022NAAC%EF%BC%9ATreeMix/">TreeMix：基于组合的数据增强方法</a></p><p class="categories"><a href="/categories/DA/">DA</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-05-26T16:00:00.000Z">2022-05-27</time></p><p class="title"><a href="/2022/05/27/%E3%80%8CGAN%E3%80%8D2021EMNLP%EF%BC%9A%E5%AF%B9LGAN%E8%BF%9B%E8%A1%8CCounter-Contrastive%E5%AD%A6%E4%B9%A0/">Counter-Contrastive 学习：训练Language GAN</a></p><p class="categories"><a href="/categories/GAN/">GAN</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">七月 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/06/"><span class="level-start"><span class="level-item">六月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/05/"><span class="level-start"><span class="level-item">五月 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">四月 2022</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DA/"><span class="tag">DA</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MixUP/"><span class="tag">MixUP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MixUp/"><span class="tag">MixUp</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mixup/"><span class="tag">Mixup</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/"><span class="tag">对比学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA/"><span class="tag">数据增强</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E4%B9%89%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97/"><span class="tag">语义相似度计算</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%B2%E8%A8%80%E7%A2%8E%E8%AF%AD/"><span class="tag">闲言碎语</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%99%8D%E7%BB%B4/"><span class="tag">降维</span><span class="tag">1</span></a></div></div></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="都灵的夏天" height="28"></a><p class="is-size-7"><span>&copy; 2022 周江峰</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>